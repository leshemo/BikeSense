{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BlueBike AI: Using AI to Predict best time to make BlueBike Trip\n",
    "$\\newline$\n",
    "Final project $\\newline$\n",
    "Professor Snyder's CS4100 Artificial Intelligence class\n",
    "$\\newline$\n",
    "Group members: Ariel Mahler, Omri Leshem, Marco Tortolani\n",
    "GitHub Repo: https://github.com/Mtortolani/bluebike-ai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation\n",
    "For this project, our group wanted to address a problem that has a tangible effect on our lives. Transportation in Boston is always a challenge for us, especially for group member Omri, who often has challenges finding a good time to grab a BlueBike. BlueBike is a subscription based service that allows you to pick up an available BlueBike from a station at any time, and return it to a station once your trip is over. The challenge is that sometimes, when going to a station, you can find that it is out of bikes, or at the end of a trip, that the docking station we were heading to doesn't have any available parking spots. Both of these are challenges that require us to look for alternative stations, which takes time and effort. We hope that through this project we can create a tool to help reduce the overall time spent finding stations to undock/dock BlueBikes, and eliminating guesswork when planning a trip."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Design Overview\n",
    "The challenge of this project is to predict the best time to take a trip in a BlueBike to have the best odds at an available bike at starting station and an available bike at end station. For us to accurately predict this, we devised 3 core components: \n",
    "1. Feed in historical BlueBike trip data and process that into something usable\n",
    "2. Develop a machine learning model that takes in historical station data to predict how many bikes would be at a station at a given time\n",
    "3. Design a controller that would query the model and apply a heuristic to deduce the best time to take a BlueBike trip.\n",
    "\n",
    "This framework allowed us to break apart the task into three individual Python classes, which helped us segment the work. Although we started off with Omri working on DataCleaning.py (the data), Marco working on BikeCountPredictor.py (the model), and Ari working on BikeCountController (the heurostic), it very quickly turned into a joint effort to figure out how to find more data to improve the model, or making the heuristic more sensible to a rider's real trip."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "This section of the program extracts the usable/necessary data from the BlueBike historical datasets (ranging from April 2022 to March 2023), and processes it for use by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import to_datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plti\n",
    "\n",
    "#balancing first\n",
    "def rebalance(year_month):\n",
    "    #NOTE: Jupyter notebook does not always work with relative path\n",
    "    # if error, replace with absolute path\n",
    "    df = pd.read_csv(\"./src/data/%s-bluebikes-tripdata.csv\" % year_month,\n",
    "            usecols=['starttime','start station id',\n",
    "                    'stoptime','end station id', 'bikeid'],\n",
    "            parse_dates=['starttime','stoptime'])\n",
    "\n",
    "    dfbike=df.sort_values(by=['bikeid','starttime'])\n",
    "    dfbike.head(10)\n",
    "\n",
    "    offset = pd.DataFrame({'starttime': pd.to_datetime('2010-09-01'),\n",
    "    'start station id':0,'stoptime': pd.to_datetime('2010-09-01'),\n",
    "    'end station id':0,'bikeid':0},index=[0])\n",
    "\n",
    "    dfbike1 = pd.concat([offset,dfbike]).reset_index(drop=True)\n",
    "    dfbike2 = pd.concat([dfbike,offset]).reset_index(drop=True)\n",
    "\n",
    "    dfbike=pd.concat ([dfbike1[['bikeid','stoptime','end station id']]\\\n",
    "                ,dfbike2[['bikeid','starttime','start station id']] ],\\\n",
    "                axis=1 )\n",
    "    dfbike.head()\n",
    "\n",
    "    dfbike.columns=['bikeid1','starttime','start station id',\\\n",
    "                    'bikeid2','stoptime','end station id']\n",
    "    dfrebal = dfbike[['starttime','start station id',\\\n",
    "                    'stoptime','end station id']].\\\n",
    "            loc[(dfbike.bikeid1==dfbike.bikeid2) & \\\n",
    "            (dfbike['start station id'] != dfbike['end station id']) ]\n",
    "    dfrebal.reset_index(drop=True, inplace=True)\n",
    "    dfrebal\n",
    "    dfrebal.to_parquet('./src/data/%s-bluebike-reblance.parquet' % year_month)\n",
    "    print(\"Rebalancing done for %s!\" % year_month)\n",
    "\n",
    "#create csv for number of bikes at particular station, using the rebalanced parquet file\n",
    "def bikeAvail(station, year_month):\n",
    "    \n",
    "    df = pd.read_csv('./src/data/%s-bluebikes-tripdata.csv' % year_month,\n",
    "            usecols=['starttime','start station id',\n",
    "                    'stoptime','end station id'],\n",
    "            parse_dates=['starttime','stoptime'])\n",
    "    dfrebal = pd.read_parquet ('./src/data/%s-bluebike-reblance.parquet' % year_month)\n",
    "    df = pd.concat([df,dfrebal])\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    dfs=df[['starttime','start station id']].assign(act=-1)\n",
    "    dfe=df[['stoptime','end station id']].assign(act=1)\n",
    "    dfs.columns=['docktime','stationid','act']\n",
    "    dfe.columns=['docktime','stationid','act']\n",
    "    dfse=pd.concat([dfs,dfe])\n",
    "\n",
    "\n",
    "    dfse.sort_values(by=['docktime'], inplace=True) \n",
    "    dfse.reset_index(drop=True, inplace=True) \n",
    "    dfse.head(100)\n",
    "\n",
    "\n",
    "    dfstations = pd.read_csv(\"./src/data/%s-bluebikes-tripdata.csv\" % year_month,\n",
    "    usecols=['start station id','start station name']).drop_duplicates()                \n",
    "    dfstations.columns=['stationid','station name']\n",
    "    dfstations.set_index('stationid',drop=True, inplace=True)\n",
    "\n",
    "    station_id = dfstations.loc[dfstations['station name']\\\n",
    "     == station].index[0]\n",
    "    dfStation = dfse.loc[(dfse.stationid==station_id) ]\n",
    "    dfStation.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    dfStation = dfStation.assign(num_bikes = dfStation.act.cumsum())\n",
    "    dfStation.at[0, 'act'] += abs(dfStation.act.cumsum().min())\n",
    "    dfStation = dfStation.assign(num_bikes = dfStation.act.cumsum())\n",
    "    dfStation['minutes'] = 0\n",
    "    dfStation = dfStation.assign(minutes =  dfStation['docktime'].dt.hour * 60 + dfStation['docktime'].dt.minute + round(dfStation['docktime'].dt.second / 60, 3))\n",
    "    dfStation = dfStation.drop('act', axis = 1)\n",
    "    print(\"Dock data generated for %s\" % station)\n",
    "\n",
    "    attachClimateData(dfStation)\n",
    "\n",
    "\n",
    "#clean climate data csv to include only daily average temp in boston over the year we're looking at. Only needs to be run once.\n",
    "def cleanClimateData():\n",
    "        dfClimate = pd.read_csv('./src/data/2022-2023-climate-data.csv',\n",
    "                usecols=['DATE','DailyAverageDryBulbTemperature'],\n",
    "                parse_dates=['DATE'])\n",
    "        dfClimate = dfClimate.dropna()\n",
    "        dfClimate.reset_index(inplace=True)\n",
    "        dfClimate.to_csv('./src/data/2022-2023-climate-data-processed.csv')\n",
    "        print(dfClimate.head(10))\n",
    "        print(dfClimate.index)\n",
    "\n",
    "#merge the climate data and the dock data so that every day has an average temperature.\n",
    "def attachClimateData(df2):\n",
    "        df1 = pd.read_csv('./src/data/2022-2023-climate-data-processed.csv',\n",
    "                usecols=['DATE','DailyAverageDryBulbTemperature'],\n",
    "                parse_dates=['DATE'])\n",
    "        df1.rename(columns = {'DATE': 'docktime'}, inplace = True)\n",
    "        df1.docktime = df1.docktime.apply(lambda x: x.date())\n",
    "        df2.docktime = df2.docktime.apply(lambda x: x.date())\n",
    "\n",
    "        merged_df = pd.merge(df2, df1, how='left', on= 'docktime')\n",
    "        merged_df.rename(columns = {'docktime': 'day'}, inplace = True)\n",
    "        merged_df.rename(columns = {'DailyAverageDryBulbTemperature': 'average_temp'}, inplace = True)\n",
    "        merged_df.to_csv('./data/2022-2023-dock-data-updated.csv', mode='a', header=False)\n",
    "        print(\"Average temp attached to dock data!\")\n",
    "\n",
    "def addMoreParams():\n",
    "       dfA = pd.read_csv('./src/data/2022-2023-dock-data-updated.csv',\n",
    "                         usecols=['day', 'stationid', 'num_bikes', 'minutes', 'average_temp'],\n",
    "                        parse_dates=['day'])\n",
    "       #rename day column to date\n",
    "       dfA.rename(columns = {'day': 'date'}, inplace = True)\n",
    "#        #add day of week\n",
    "       dfA['day'] = dfA.date.apply(lambda x: x.date().day)\n",
    "       dfA['month'] = dfA.date.apply(lambda x: x.date().month)\n",
    "\n",
    "\n",
    "       #add weekday (as in Monday, Tuesday, etc.)\n",
    "       dfA['day_of_week'] = dfA.date.apply(lambda x: x.weekday())\n",
    "\n",
    "       dfA.to_csv('./data/2022-2023-dock-data-updated-fo-real.csv', index=False)\n",
    "\n",
    "def doTheThing():\n",
    "        array_of_year_months = [\"202302\", \"202301\", \"202212\", \"202211\", \"202210\", \"202209\", \"202208\", \"202207\", \"202206\", \"202205\", \"202204\"]\n",
    "        start_station = \"Boylston St at Jersey St\"\n",
    "        end_station = \"Ruggles T Stop - Columbus Ave at Melnea Cass Blvd\"\n",
    "        for year_month in array_of_year_months:\n",
    "                rebalance(year_month)\n",
    "                bikeAvail(start_station, year_month)\n",
    "                bikeAvail(end_station, year_month)\n",
    "\n",
    "# addMoreParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>stationid</th>\n",
       "      <th>num_bikes</th>\n",
       "      <th>minutes</th>\n",
       "      <th>average_temp</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>342</td>\n",
       "      <td>13</td>\n",
       "      <td>77.933</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>342</td>\n",
       "      <td>14</td>\n",
       "      <td>105.867</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>342</td>\n",
       "      <td>15</td>\n",
       "      <td>106.333</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>342</td>\n",
       "      <td>14</td>\n",
       "      <td>491.317</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>342</td>\n",
       "      <td>13</td>\n",
       "      <td>492.850</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112565</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>1413.533</td>\n",
       "      <td>48.0</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112566</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>1423.400</td>\n",
       "      <td>48.0</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112567</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>1423.717</td>\n",
       "      <td>48.0</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112568</th>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>13.550</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112569</th>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>13.600</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112570 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  stationid  num_bikes   minutes  average_temp  day  month  \\\n",
       "0       2023-03-01        342         13    77.933          38.0    1      3   \n",
       "1       2023-03-01        342         14   105.867          38.0    1      3   \n",
       "2       2023-03-01        342         15   106.333          38.0    1      3   \n",
       "3       2023-03-01        342         14   491.317          38.0    1      3   \n",
       "4       2023-03-01        342         13   492.850          38.0    1      3   \n",
       "...            ...        ...        ...       ...           ...  ...    ...   \n",
       "112565  2022-04-30         12         25  1413.533          48.0   30      4   \n",
       "112566  2022-04-30         12         24  1423.400          48.0   30      4   \n",
       "112567  2022-04-30         12         23  1423.717          48.0   30      4   \n",
       "112568  2022-05-01         12         24    13.550          53.0    1      5   \n",
       "112569  2022-05-01         12         25    13.600          53.0    1      5   \n",
       "\n",
       "        day_of_week  \n",
       "0                 2  \n",
       "1                 2  \n",
       "2                 2  \n",
       "3                 2  \n",
       "4                 2  \n",
       "...             ...  \n",
       "112565            5  \n",
       "112566            5  \n",
       "112567            5  \n",
       "112568            6  \n",
       "112569            6  \n",
       "\n",
       "[112570 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFilename = \"./src/data/2022-2023-dock-data-updated-fo-real.csv\"\n",
    "df = pd.read_csv(dataFilename)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation & Testing\n",
    "Although the task of predicting optimal bike depature time seemed like a daunting challenge, it was made much more clear when we divided the model into seperate cleaning, predicting, and heuristic measurement. As the data cleaning took place and we were afforded more parameters as inputs, we were able to improve our models. Our first model was a simple linear regression which had a large error rate and a an r2 value of less than 0.1. With only the minutes in the day and the temperature as the inpui=t variable, the model had almost no ability to properly predict the amount of bikes in a station at a given time. As we provided more variables such as day of the week and month, we were able to implement more complex models such as a knn regressor and a decision tree regressor. Being familiar with complex models we knew we had to hyperparameter tune (particularly for decision trees as they tend to strongly overfit with too many layers). After hyperparameter tuning our new models with the new bike station historical data, we were able to achieve our best running model which is a knn regressor with a MSE of ~8 and a r2 value of ~0.62. Although this doesn't meet the bar for professional models, at least the model is improving substantially from the data we are feeding it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for decision tree model on station 342:\n",
      "The best parameters for decision tree model from gridsearch are {'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 4}\n",
      "The test MSE for decision tree model is:  10.159631777798728\n",
      "The R2 score decision tree model is:  0.43091909123527683\n",
      "\n",
      "The decision tree model predicts that station 342 at minutes 950 and temp 47 will have 4.443478260869565 bikes\n",
      "\n",
      "The decision tree model predicts that station 342 at minutes 1200 and temp 64 will have 12.346456692913385 bikes\n",
      "\n",
      "Results for knn model on station 12:\n",
      "The best parameters for knn model from gridsearch are {'n_neighbors': 5, 'weights': 'distance'}\n",
      "The test MSE for knn model is:  16.854413213813473\n",
      "The R2 score knn model is:  0.6179610333816541\n",
      "\n",
      "The knn model predicts that station 12 at minutes 950 and temp 47 will have [10.64193664] bikes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "class BikeCountPredictor:\n",
    "    def __init__(self, dataFilename='./src/data/2022-2023-dock-data-updated-fo-real.csv'):\n",
    "        \n",
    "        #initialization functions\n",
    "        self.stationData = self.loadDataByStation(dataFilename)\n",
    "        self.stationModels = {} # self.stationModels[stationId: int][desired_model: str] = model\n",
    "        \n",
    "    def loadDataByStation(self, allStationDataFilename: str) -> dict[pd.DataFrame]:\n",
    "        dfAllStations = pd.read_csv(allStationDataFilename)\n",
    "        dfAllStations = dfAllStations.dropna()\n",
    "        uniqueStationIds = dfAllStations['stationid'].unique()\n",
    "        return {stationId : dfAllStations.loc[dfAllStations['stationid']==stationId] for stationId in uniqueStationIds}\n",
    "    \n",
    "    def existsStationData(self, stationId: int) -> None:\n",
    "        if not self.stationData:\n",
    "            raise Exception(\"There is no station data loaded.\")\n",
    "        if stationId not in self.stationData:\n",
    "            raise Exception(\"There is no station data for this particular station.\")\n",
    "        \n",
    "    def createModel(self, stationId: int, desired_model: str, verbose: bool = True):\n",
    "        self.existsStationData(stationId)\n",
    "        xCols = [\"minutes\", \"average_temp\",\"day\",\"month\",\"day_of_week\"]\n",
    "        dfX = self.stationData[stationId][xCols]\n",
    "        dfY = self.stationData[stationId][[\"num_bikes\"]]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(dfX.to_numpy(), dfY.to_numpy(), test_size=0.20, random_state=123)\n",
    "        if (verbose): print(f\"\\nResults for {desired_model} model on station {stationId}:\")\n",
    "        if desired_model == \"linear\":\n",
    "            params = {}\n",
    "            model = GridSearchCV(LinearRegression() , param_grid=params, scoring='neg_mean_squared_error',cv=5)\n",
    "        elif desired_model == \"knn\":\n",
    "            params = [{'n_neighbors': [3, 5, 7, 9],\n",
    "                       'weights': ['uniform', 'distance']}]\n",
    "            model = GridSearchCV(KNeighborsRegressor() , param_grid=params,scoring='neg_mean_squared_error',cv=5)\n",
    "        elif desired_model == \"decision tree\":\n",
    "            params = {'max_depth': range(1,10,2), \n",
    "                          \"min_samples_split\": range(2,10,2), \n",
    "                          \"min_samples_leaf\": range(1,10,2)}\n",
    "            model = GridSearchCV(DecisionTreeRegressor() , param_grid=params,scoring='neg_mean_squared_error',cv=5)\n",
    "        else:\n",
    "            raise Exception(f\"Desired model type {desired_model} does not exist\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        if (verbose):\n",
    "            print(f\"The best parameters for {desired_model} model from gridsearch are {model.best_params_}\")\n",
    "            print(f\"The test MSE for {desired_model} model is: \", mean_squared_error(y_test,y_pred))\n",
    "            print(f\"The R2 score {desired_model} model is: \", r2_score(y_test,y_pred))\n",
    "        if not stationId in self.stationModels:\n",
    "            self.stationModels[stationId] = {}\n",
    "        self.stationModels[stationId][desired_model] = model\n",
    "        return model\n",
    "        \n",
    "\n",
    "    def existsStationModel(self, stationId: int, desired_model: str):\n",
    "        return stationId in self.stationModels and desired_model in self.stationModels[stationId]\n",
    "    \n",
    "    def predictBikeCount(self, stationId, minutes: float, temp: float, day: int, month: int, day_of_week: int, desired_model: str, verbose:bool = True) -> int:\n",
    "        if not self.existsStationModel(stationId, desired_model):\n",
    "            model =  self.createModel(stationId, desired_model, verbose)\n",
    "        model = self.stationModels[stationId][desired_model]\n",
    "        y_pred = model.predict([[minutes, temp, day, month, day_of_week]])\n",
    "        if (verbose):\n",
    "            print(f\"\\nThe {desired_model} model predicts that station {stationId} at minutes {minutes} and temp {temp} will have {y_pred[0]} bikes\")\n",
    "        return y_pred[0]\n",
    "    \n",
    "def main():\n",
    "    BCP = BikeCountPredictor()\n",
    "    stationId = 342\n",
    "    minutes = 950 #15:50\n",
    "    temp = 47\n",
    "    day = 5\n",
    "    month = 7\n",
    "    day_of_week = 0\n",
    "    desired_model = 'decision tree'\n",
    "    BCP.predictBikeCount(stationId, minutes, temp, day, month, day_of_week, desired_model)\n",
    "    \n",
    "    stationId = 342\n",
    "    minutes = 1200 \n",
    "    temp = 64\n",
    "    day = 15\n",
    "    month = 5\n",
    "    day_of_week = 0\n",
    "    desired_model = 'decision tree'\n",
    "    BCP.predictBikeCount(stationId, minutes, temp, day, month, day_of_week, desired_model)\n",
    "    \n",
    "    stationId = 12\n",
    "    minutes = 950 #15:50\n",
    "    temp = 47\n",
    "    day = 25\n",
    "    month = 9\n",
    "    day_of_week = 2\n",
    "    desired_model = 'knn'\n",
    "    BCP.predictBikeCount(stationId, minutes, temp, day, month, day_of_week, desired_model)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for linear model on station 12:\n",
      "The best parameters for linear model from gridsearch are {}\n",
      "The test MSE for linear model is:  39.694464316197084\n",
      "The R2 score linear model is:  0.10024561902872975\n",
      "\n",
      "Results for linear model on station 342:\n",
      "The best parameters for linear model from gridsearch are {}\n",
      "The test MSE for linear model is:  17.348386236604092\n",
      "The R2 score linear model is:  0.028248698274460304\n",
      "\n",
      "Results for decision tree model on station 12:\n",
      "The best parameters for decision tree model from gridsearch are {'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 4}\n",
      "The test MSE for decision tree model is:  18.671852961219738\n",
      "The R2 score decision tree model is:  0.5767651285357269\n",
      "\n",
      "Results for decision tree model on station 342:\n",
      "The best parameters for decision tree model from gridsearch are {'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 6}\n",
      "The test MSE for decision tree model is:  10.16411908228786\n",
      "The R2 score decision tree model is:  0.4306677396732882\n",
      "\n",
      "Results for knn model on station 12:\n",
      "The best parameters for knn model from gridsearch are {'n_neighbors': 5, 'weights': 'distance'}\n",
      "The test MSE for knn model is:  16.854413213813473\n",
      "The R2 score knn model is:  0.6179610333816541\n",
      "\n",
      "Results for knn model on station 342:\n",
      "The best parameters for knn model from gridsearch are {'n_neighbors': 5, 'weights': 'distance'}\n",
      "The test MSE for knn model is:  8.75467183361988\n",
      "The R2 score knn model is:  0.5096164199670635\n"
     ]
    }
   ],
   "source": [
    "# Display results for creating and testing each model type on each station\n",
    "BCP = BikeCountPredictor()\n",
    "desired_model_types = ['linear', 'decision tree', 'knn']\n",
    "\n",
    "for desired_model in desired_model_types:\n",
    "    BCP.createModel(12, desired_model, verbose=True)\n",
    "    BCP.createModel(342, desired_model, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic and Interactability\n",
    "The most complex part of this portion was designing a curve for the heuristic that would make sense; we needed to ensure that a case that had no bikes or spaces would not be considered, and that an increasing quantity of something would begin to lose value compared to the increase of others. For example, it is not necessarily a better case that there will be 15 bikes waiting for you, if there is only 1 space waiting for you. We decided to go with a logarithmic curve, which when supplemented with raising the input value to a power and scaling the curve meant the difference between 1 and 5 bikes was much larger than 5-10 and etcetera. $\\newline$\n",
    "The next step was to develop the interactive component of the machine. To do this, we prompt the user for the necessary materials we need to produce a query for our model, then run the heuristic on the next 30 minutes from the current moment to give an optimal time to leave. The 30 minute period was hard coded, however in the future we could simply add another question that allows the user to pick length of time, or even start moment to search for. From here, we move upwards from the start point, the point of this being that if there is a tie in the heuristic, the preference should go to the earlier time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The best moment to leave would be at 21:46\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from BikeCountPredictor import BikeCountPredictor\n",
    "from datetime import time as t\n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "\n",
    "class BikeCountController:\n",
    "    def __init__(self):\n",
    "        self.oracle = BikeCountPredictor()\n",
    "\n",
    "\n",
    "    def heuristic(self, startStationId, endStationId, minutes, time, temp,day, month, day_of_week, model = 'decision tree'):\n",
    "        bikes = self.oracle.predictBikeCount(startStationId, minutes, temp, day, month, day_of_week, model, False)\n",
    "        spaces = 26 - self.oracle.predictBikeCount(endStationId, (minutes + time), temp, day, month, day_of_week, model, False)\n",
    "        if bikes == 0 or spaces == 0:\n",
    "            return -sys.maxsize\n",
    "        else:\n",
    "            return self.curve(spaces) + self.curve(bikes)\n",
    "\n",
    "    # Mathematical model for the heuristic to follow\n",
    "    def curve(self, num):\n",
    "        return 10 * math.log(num**3 + 1)\n",
    "\n",
    "\n",
    "    def initiateBikeQuery(self):\n",
    "        # Query user for settings\n",
    "        startStation = int(input(\"Please enter the start station: \"))\n",
    "        endStation = int(input(\"Please enter the end station: \"))\n",
    "        time = int(input(\"Please enter the length of time for the trip in minutes: \"))\n",
    "        temp = int(input(\"What is the temperature at the moment in fahrenheit? \"))\n",
    "        now = datetime.now()\n",
    "        minutes = (60 * now.hour) + now.minute\n",
    "        day = now.day\n",
    "        month = now.month\n",
    "        day_of_week = now.weekday()\n",
    "        leave = (0, minutes)\n",
    "\n",
    "        for i in range(30):     # Evaluate the next 30 minutes\n",
    "            heur = self.heuristic(startStation, endStation, minutes, time, temp, day, month, day_of_week)\n",
    "            if (heur > leave[0]):\n",
    "                leave = (heur, minutes)\n",
    "            minutes = minutes + 1\n",
    "        # Set result to a readable format\n",
    "        minute = minutes % 60\n",
    "        hour = int((minutes - minute) / 60)\n",
    "        print(\"\\nThe best moment to leave would be at\", t(hour, minute, 0).strftime(\"%H:%M\"))\n",
    "        \n",
    "def main():\n",
    "    # Prompts for the query\n",
    "    BCC = BikeCountController()\n",
    "    BCC.initiateBikeQuery()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The best moment to leave would be at 21:48\n"
     ]
    }
   ],
   "source": [
    "BCC = BikeCountController()\n",
    "\n",
    "# Sample data\n",
    "# Explicit varibles, time data pulled from datetime.now()\n",
    "startStationId = 342\n",
    "endStationId = 12\n",
    "lengthOfTrip = 15\n",
    "temp = 64\n",
    "BCC.initiateBikeQuery()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
